## 项目复盘-1
最近在复盘之前接手过的一项目的时候，想到了之前遇到的一个问题。

### 背景
之前的项目是一个日志系统，项目的流量和数据量都巨大，一天的量应该在10TB以上。日志数据从机器上采集以后，会先吐到Kafka中。kafka在这个项目中主要起到一个缓冲层，分发层，解耦层的作用。在下游系统中，日志系统的主站会根据日志的方向不同，分别按照不同逻辑处理，比如需要检索则利用CI/CD部署一个服务将数据存入到ES，而如果需要OLAP场景，则将其存入到clickhouse中，或者其他流向


## 为什么选择kafka

在日志这个场景下，我们对中间件的核心诉求是：

	1.	高吞吐 —— 每秒要能支撑数十万到百万条日志；

	2.	可扩展性强 —— 节点容易水平扩展；

	3.	支持多路消费 —— 同一份日志数据可能被多个系统消费；

	4.	顺序性与持久化良好；

	5.	可靠性高，可容忍短暂下游故障（削峰+缓冲）。


| 对比维度 | **Kafka** | **RocketMQ** | **RabbitMQ** |
|-----------|------------|---------------|----------------|
| **吞吐量** | ⭐⭐⭐⭐ 极高，单机百万级 | ⭐⭐⭐ 较高，10万~几十万 | ⭐ 较低，几万级 |
| **延迟** | 毫秒级（顺序写） | 毫秒级 | 毫秒~秒级 |
| **存储模型** | 顺序写磁盘 + PageCache，支持长期持久化 | 文件存储（CommitLog），支持长期持久化 | 内存为主，持久化需额外代价 |
| **消费模型** | Pull + Consumer Group，天然支持多消费者 | Pull，支持广播/集群模式 | Push 模式，消费能力有限 |
| **多消费者支持** | 非常优秀（多 group 独立 offset） | 较好 | 一般，消息分发后删除 |
| **扩展性** | 优秀（分区水平扩展） | 良好（基于队列分片） | 较差（单队列难扩展） |
| **生态支持** | 非常完善（ELK、Flink、Spark） | 主要在国内应用 | 传统系统或金融业务 |
| **运维复杂度** | 中等（需调优） | 稍高（配置复杂） | 低（功能简单） |



#### 结合日志系统场景分析选择原因

1. Kafka 天生适合日志流式处理

Kafka 最初由 LinkedIn 设计，就是为了解决大规模日志管道问题。
它的核心模型就是：

	append-only、顺序写、持久化的分布式日志系统

所以和我们的需求几乎是“天然契合”：
	•	Filebeat → Kafka → Logstash 是官方推荐链路；
	•	Kafka 的 topic-partition 模型可以高效地分区并行处理日志。


2. 高吞吐与可扩展性

日志场景的核心是吞吐量。
Kafka 基于磁盘顺序写 + PageCache，性能非常高：
	•	单节点轻松达到数十万条/秒；
	•	水平扩展简单，只需增加 broker 与 partition；
	•	而 RabbitMQ 扩展困难，RocketMQ 虽能扩展但生态支持略弱。

3. 多路消费能力

在日志系统中，同一份日志可能被：
	•	Logstash 消费写入 Elasticsearch；
	•	Flink 消费做实时聚合；
	•	Spark 或 Hadoop 消费做离线分析。

Kafka 的 Consumer Group 模型 支持同一 topic 被多个 group 独立消费，每个 group 有自己独立的 offset，完美满足这种“一份数据，多份用途”的需求。

RabbitMQ 就不太适合这种模式 —— 消息被一个消费者消费后就会被删除。


4. 持久化与可回溯能力

Kafka 将消息持久化到磁盘，并根据 retention policy 保留数据。
	•	即使消费端挂了，也可以根据 offset 从任意位置重新消费；
	•	这对日志分析和补数非常关键；
	•	RocketMQ 也支持类似功能，但社区生态不如 Kafka 成熟；
	•	RabbitMQ 一旦消费即删除，无法回溯。



## Kafka作用分析
1. 解耦生产与消费


	•	Filebeat 是生产者：持续将日志采集并写入 Kafka；


	•	下游系统是消费者：异步地从 Kafka 拉取日志进行处理与存储。

    这种方式有几个好处：


	•	生产者（Filebeat）不需要关心消费端的处理速度；


	•	消费者可以随时增加或减少，互不影响；


	•	任意消费端挂掉不会阻塞日志采集，系统更稳定。

2. 缓冲和削峰

Kafka 天生就是一个高性能消息队列，能以磁盘顺序写入方式存储大量数据。
这意味着它可以：

	•	缓冲突发的大量日志；

	•	平滑下游消费端的压力；

	•	防止日志高峰期造成系统崩溃或丢失。

3. 支持多路消费

Kafka 支持多个 consumer group。
这意味着：

	•	一份日志可以被多个系统消费；

	•	例如：

	•	Logstash 消费日志送 ES

	•	Flink 消费日志做实时分析

	•	Spark 或 Hadoop 消费日志做离线计算

3. 支持多路消费

Kafka 支持多个 consumer group。
这意味着：

	•	一份日志可以被多个系统消费；

	•	例如：

	•	Logstash 消费日志送 ES

	•	Flink 消费日志做实时分析

	•	Spark 或 Hadoop 消费日志做离线计算

### 使用kafka遇到的问题和解决方案
在日志系统中，最常出现的就是日志延迟。而导致延迟的最主要的原因就是消息积压。

在使用kafka作为消息中间件时，遇到的最多的问题就是消息堆积。当业务高峰期，产生的日志过多或者速率过快的情况下，就可能产生消息积压。

当出现消息积压的情况时，首先要确定是什么原因导致的。消息积压的本质原因就是消费者速率和生产者速率的不匹配。
因此主要原因可能是

生产速度过高：: 生产者在短时间内发送了大量消息。 

消费者处理能力不足：: 单个消费者处理速度慢、消费逻辑耗时过长，或者消费者数量不足。 

消费者异常：: 部分消费者出现宕机、死锁、bug 或网络故障。 

消费并行度设置不当：: 消费者数量少于分区数，导致部分分区没有被消费，或者消费者数量远超分区数，造成资源浪费。 

服务端问题：: Broker 自身压力大。 

所以有以下决方案：
消费者端：
  增加消费者数量： 可以通过增加消费进程实例或在同一进程内增加消费线程来提升并行度，但消费实例数量不应超过Topic 的分区数。 

  优化消费逻辑： 减少消费者端处理逻辑的耗时，例如优化数据查询、减少第三方接口调用等，提高单条消息的处理速度。 

  调整拉取参数： 增大 max.poll.records 参数，使消费者每次能够拉取更多消息，并确保处理时间大于拉取时间。 
  
生产者端

   增加随机后缀： 在消息Key 中加入随机后缀，以实现消息的均衡分配到不同的分区，但可能会导致全局顺序性丢失，需根据业务场景决定是否采用。

   熔断或限流： 当出现堆积时，可以通过熔断机制临时停止消息生产，或将消息转发到其他Topic。 
服务端

   增加Topic 分区数： 在不影响业务的情况下，适当地增加Topic 的分区数量，可以并行处理更多的消息。 
     
   合理设置消息保留策略： 通过 log.retention.hours 和 log.retention.bytes 参数，控制消息在Broker 中的存储时间或大小，让过期消息自动被清理。

### 服务稳定性建设
对于kafka这种组件，可以使用额外的监控指标判断他的健康程度。在上个项目中，使用prometheus来监控kafka的积压程度